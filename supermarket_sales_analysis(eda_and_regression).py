# -*- coding: utf-8 -*-
"""Supermarket Sales Analysis(EDA and Regression).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MiFWXi4XGuhevOF65mDs9kRjJ7CtqoBE

# **Supermarket Sales Analysis(EDA and Regression)**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive/')
# %cd /gdrive

ls

cd/gdrive/My Drive/Supermarket sales_EDA/

ls

"""**Importing Packages**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sb
# %matplotlib inline

"""**Import of the CSV file**"""

df=pd.read_csv("/gdrive/My Drive/Supermarket sales_EDA/Stores.csv")

"""**Top 5 rows of the data**"""

df.head()

df.info()

"""**Finding out the number of empty cells in the dataset**"""

df.isnull().sum()

"""There exists no empty cells in the dataset

**Descriptive Statistics of the Dataset**
"""

df.describe()

"""**Finding out the range of the Store Sales**"""

rng=df['Store_Sales'].max()-df['Store_Sales'].min()
rng

"""**Conducting z test to find out outliers**

We have assumed the data to be normal and to prove its normality, we are conducting the z test
"""

x=df["Store_Sales"]
mean=df["Store_Sales"].mean()
std=df["Store_Sales"].std()
z= (x-mean)/std
z

"""**Adding the z values to the dataset**"""

df["z-score"]=z

df.head()

"""**Plotting the z values**"""

ax=plt.figure(figsize=(10,6))
sb.distplot(df['z-score'],color="red")

"""There are certain values present outside the threshold of 99.7%

**Outlier in the Dataset is**
"""

outl=df[df["z-score"]>3]
outl

"""**Scatterplot of the Dataset**"""

sb.pairplot(df,palette='Paired')

"""**Density curve showing the frequency of number of items present in each store**"""

ax=plt.figure(figsize=(10,6))
sb.distplot(df["Items_Available"],color="blue",bins=100)

"""**Scatterplot between the Store Area and Items Available**"""

ax=plt.figure(figsize=(10,6))
sb.scatterplot(x='Store_Area',y='Items_Available',data=df,color="green")

"""**Scatterplot between the Store Sales and Items Available**"""

ax=plt.figure(figsize=(10,6))
sb.scatterplot(x='Store_Sales',y='Items_Available',data=df,color="orange")

"""**Scatterplot between the Store Sales and Store Area**"""

ax=plt.figure(figsize=(10,6))
sb.scatterplot(x='Store_Sales',y='Store_Area',data=df,color="purple")

"""**Scatterplot between the Store Sales and Daily Customer Count**"""

ax=plt.figure(figsize=(10,6))
sb.scatterplot(x='Store_Sales',y='Daily_Customer_Count',data=df,color="brown")

"""**Correlation of the different variables**"""

ax=plt.figure(figsize=(10,6))
corr=df.corr()
sb.heatmap(corr,linewidths=1,linecolor='white',annot=True)

"""Shows Store Area correlated to Items Available

# Model 1:

**Assigning the independant and depenant variables as X and y respectively**
"""

X=df[["Daily_Customer_Count"]]
y=df[["Store_Sales"]]

"""**Importing Train Test Split**"""

from sklearn.model_selection import train_test_split

"""**Assigning test size to 20%**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Importing Linear Regression**"""

from sklearn.linear_model import LinearRegression

lr=LinearRegression()

"""**Fitting the data in the model**"""

lr.fit(X_train,y_train)

"""**The Intercept of the data**"""

intercept=lr.intercept_
intercept

"""**Coefficient of the data**"""

coef=lr.coef_[0]
coef

"""**Predicting the data**"""

pred = lr.predict(X_test)

"""**Plotting the testing and the predicted data**"""

plt.plot(y_test, pred)

"""There looks no explanation or fitting through the model

**Finding the R squared value to find out how well the model is explained**
"""

from sklearn.metrics import r2_score
r2=(r2_score(y_test,pred))
print(r2*100)

"""The model looks very undexplained maybe due to underfitting

**Absolute Error in the data**
"""

from sklearn.metrics import mean_absolute_error
error = mean_absolute_error(y_test, pred)
error

"""The model has a high error making it a failed model

# **Model 2**

**Assigning the independant and dependant variables**
"""

X1=df[["Store_Area"]]
y1=df[["Items_Available"]]

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)

lr1 = LinearRegression()

"""**Fitting the new model into linear regression**"""

lr1.fit(X1_train,y1_train)

"""**Intercept of the model**"""

intercept1=lr1.intercept_
intercept1

"""**Coefficient of the model**"""

coef1=lr1.coef_[0]
coef1

pred1 = lr1.predict(X1_test)

"""**Plotting the test and predicted data**"""

plt.plot(y1_test, pred1)

"""There seems to be relation between tested and predicted data

**Finding out the R squared data**
"""

from sklearn.metrics import r2_score
r2_1=(r2_score(y1_test,pred1))
print(r2_1*100)

"""The model is able to explain 99% of the data

**Absolute error in the data**
"""

from sklearn.metrics import mean_absolute_error
error1 = mean_absolute_error(y1_test, pred1)
error1

"""The data has low error

**Conclusion**
* Model 2 is well explained and thus the model stands
* the Model is 99% explained
* Thus we find that an increase in Store Area leads to increase in Items Available and vice versa
"""